# Comparing-LSTM-and-BERT-for-Text-Classification
* Compared the performance of Bidirectional LSTM and BERT for sarcasm detection
<p> In this research proposal, text classification is implemented using two different models, LSTM and BERT. To train LSTM for text classification, each word embedding, Word2vec and GloVe, is used to help the model reflect the similarity and relationships among the words. LSTM with word embeddings and BERT were trained with the news headline dataset for sarcasm detection, and their performances were analyzed from quantitive and qualitative perspectives. </p>

